{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pittsburgh250k Feature DB 만들기\n",
    "\n",
    "Pittsburgh250k 이미지에서 CNN feature를 추출해 `npz`로 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import timm\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행 환경 설정\n",
    "# 노트북 실행 위치에 따라 데이터 경로를 자동으로 맞춘다.\n",
    "cwd = Path.cwd()\n",
    "candidates = [\n",
    "    cwd / 'data' / 'Pittsburgh250k',\n",
    "    cwd / 'Netvlad_vanila' / 'data' / 'Pittsburgh250k',\n",
    "]\n",
    "\n",
    "DATA_ROOT = next((p for p in candidates if p.exists()), candidates[0])\n",
    "OUT_DIR = DATA_ROOT.parent.parent / 'feature_db'\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 4\n",
    "IMG_SIZE = 256\n",
    "MAX_IMAGES = 5000  # 빠른 검증용. 전체 추출 시 None\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('cwd:', cwd)\n",
    "print('device:', device)\n",
    "print('data root:', DATA_ROOT)\n",
    "print('out dir:', OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 경로 수집\n",
    "image_paths = sorted([p for p in DATA_ROOT.rglob('*.jpg') if p.is_file()])\n",
    "if MAX_IMAGES is not None:\n",
    "    image_paths = image_paths[:MAX_IMAGES]\n",
    "\n",
    "print('num images:', len(image_paths))\n",
    "if len(image_paths) == 0:\n",
    "    raise RuntimeError(f'No jpg images found under: {DATA_ROOT}')\n",
    "\n",
    "print('sample path:', image_paths[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PittsburghImageDataset(Dataset):\n",
    "    def __init__(self, paths, transform=None):\n",
    "        self.paths = paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        image = Image.open(path).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, str(path.relative_to(DATA_ROOT))\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "dataset = PittsburghImageDataset(image_paths, transform=transform)\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=(device.type == 'cuda'),\n",
    ")\n",
    "\n",
    "print('dataset size:', len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16 feature extractor (conv feature map)\n",
    "# 인터넷이 없어서 pretrained 가중치를 못 받는 환경을 대비해 fallback 처리\n",
    "try:\n",
    "    model = timm.create_model('vgg16', pretrained=True, features_only=True, out_indices=(4,))\n",
    "except Exception as e:\n",
    "    print('pretrained weight load failed, fallback to random init:', e)\n",
    "    model = timm.create_model('vgg16', pretrained=False, features_only=True, out_indices=(4,))\n",
    "\n",
    "model = model.to(device).eval()\n",
    "\n",
    "all_features = []\n",
    "all_paths = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, rel_paths in tqdm(loader, total=len(loader)):\n",
    "        images = images.to(device, non_blocking=True)\n",
    "\n",
    "        feat_map = model(images)[0]                 # [B, C, H, W]\n",
    "        feat_vec = F.adaptive_avg_pool2d(feat_map, 1).flatten(1)  # [B, C]\n",
    "\n",
    "        all_features.append(feat_vec.cpu().numpy().astype(np.float32))\n",
    "        all_paths.extend(rel_paths)\n",
    "\n",
    "features = np.concatenate(all_features, axis=0)\n",
    "print('features shape:', features.shape)\n",
    "print('num paths:', len(all_paths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장\n",
    "tag = 'all' if MAX_IMAGES is None else f'first{MAX_IMAGES}'\n",
    "out_path = OUT_DIR / f'pittsburgh250k_vgg16_gap_{tag}.npz'\n",
    "\n",
    "np.savez_compressed(\n",
    "    out_path,\n",
    "    features=features,\n",
    "    paths=np.array(all_paths, dtype=object),\n",
    ")\n",
    "\n",
    "print('saved:', out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장 결과 확인\n",
    "loaded = np.load(out_path, allow_pickle=True)\n",
    "print('keys:', loaded.files)\n",
    "print('features:', loaded['features'].shape, loaded['features'].dtype)\n",
    "print('paths:', loaded['paths'].shape)\n",
    "print('first path:', loaded['paths'][0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}