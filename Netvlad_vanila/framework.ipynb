{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43e8191f",
   "metadata": {},
   "source": [
    "# NetVLAD Tutorial\n",
    "아래 코드는 https://github.com/Nanne/pytorch-NetVlad 와, https://github.com/Relja/netvlad 를 검토하여 작성했습니다. \n",
    "\n",
    "0. Header \n",
    "\n",
    "1. Wholedata dataset load\n",
    "  - positive_within_thr : Test/Eval 용\n",
    "  - nontrivial_posisitive : Train용\n",
    "  - potential_negatives \n",
    "\n",
    "2. define Network  \n",
    "\n",
    "3. First Run  \n",
    "  - model.eval()+torch.no_grad()\n",
    "  - store feature_vector of images (query, db)\n",
    "\n",
    "4. TripletDataset mining\n",
    "  - set triplet\n",
    "     --collate_fn (query, positive, negative)\n",
    "\n",
    "4. Train Epoch, Feature extraction, train network\n",
    "   - model.train()\n",
    "\n",
    "5. Back to #.4 . update triplet, especiall feature_vector. \n",
    "   do loop until epoch is over\n",
    "\n",
    "6. test / eval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6fcb4f",
   "metadata": {},
   "source": [
    "# Header / Preprocessing\n",
    " - 동작을 위한 라이브러리\n",
    " - 데이터 경로 및 파일 읽기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbfe9d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lairpeteryksong/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Torch Library\n",
    "import torch\n",
    "import timm\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch.utils.data.dataset import Subset\n",
    "import torchvision.models as models\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "#Standard Library\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "import random\n",
    "\n",
    "# Vector library\n",
    "import sklearn\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a75f0da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "matStruct[0] :train\n",
      "matStruct[1] :[array(['000/000021_pitch1_yaw1.jpg'], dtype='<U26')]\n",
      "matStruct[2] :[585323.61300252 585323.61300252 585323.61300252 ... 584463.92173637\n",
      " 584463.92173637 584463.92173637]\n",
      "matStruct[3] :[array(['001/001381_pitch1_yaw1.jpg'], dtype='<U26')]\n",
      "matStruct[4] :[585089.36032141 585089.36032141 585089.36032141 ... 584861.3359102\n",
      " 584861.3359102  584861.3359102 ]\n",
      "matStruct[5] :[91464]\n",
      "matStruct[6] :[7824]\n",
      "matStruct[7] :[25]\n",
      "matStruct[8] :[625]\n",
      "matStruct[9] :[100]\n",
      "pitts250k_train.mat\n"
     ]
    }
   ],
   "source": [
    "root_dir = './data/Pittsburgh250k/'  #dbData file\n",
    "struct_dir = os.path.join(root_dir, 'netvlad_v100_datasets/datasets/')\n",
    "structFile = 'pitts250k_train.mat'\n",
    "queries_dir = os.path.join(root_dir, 'queries_real/')\n",
    "\n",
    "\n",
    "def parse_dbStruct(structfile, struct_dir):\n",
    "\n",
    "    structfile\n",
    "    dataset = structfile  #db의 이름을 넣기 위한 위치\n",
    "\n",
    "    mat = loadmat(os.path.join(struct_dir,structfile))\n",
    "\n",
    "    matStruct = mat['dbStruct'].item()\n",
    "\n",
    "    #debugging 용 출력\n",
    "    print(len(matStruct))\n",
    "    first_col = list(map(lambda x: x[0], matStruct))\n",
    "    for i in range(len(matStruct)):\n",
    "        print(f\"matStruct[{i}] :{first_col[i]}\")\n",
    "\n",
    "    whichSet = matStruct[0].item()\n",
    "\n",
    "    dbImage = [f[0].item() for f in matStruct[1]]  #이미지리스트\n",
    "    utmDb = matStruct[2].T\n",
    "\n",
    "    qImage = [f[0].item() for f in matStruct[3]] #쿼리 이미지\n",
    "    utmQ = matStruct[4].T\n",
    "\n",
    "    numDb = matStruct[5].item()\n",
    "    numQ = matStruct[6].item()\n",
    "\n",
    "    posDistThr = matStruct[7].item()  #25\n",
    "    posDistSqThr = matStruct[8].item() #625 --> 25^2\n",
    "    nonTrivPosDistSqThr = matStruct[9].item() #100 -->10^2\n",
    "\n",
    "    return dbStruct(whichSet, dataset, dbImage, utmDb, qImage, \n",
    "        utmQ, numDb, numQ, posDistThr, \n",
    "        posDistSqThr, nonTrivPosDistSqThr)\n",
    "\n",
    "dbStruct = namedtuple('dbStruct', ['whichSet', 'dataset', \n",
    "    'dbImage', 'utmDb', 'qImage', 'utmQ', 'numDb', 'numQ',\n",
    "    'posDistThr', 'posDistSqThr', 'nonTrivPosDistSqThr'])\n",
    "\n",
    "test = parse_dbStruct('pitts250k_train.mat',struct_dir)\n",
    "print(test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3ace5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataLoader 를 instantiation할때 사용할 transform 선언\n",
    "def input_transform():\n",
    "    return transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                               std=[0.229, 0.224, 0.225]),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01fcc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 데이터셋 클래스 하나로, triplet을 구성하기 위한 초기 분류도 함께 수행한다. \n",
    "class WholeDatset(data.Dataset):\n",
    "\n",
    "    def __init__(self, rootPath, stPath, qPath, structFile, transform=None, onlyDB=False, ):\n",
    "        super().__init__()  #parent class 초기화용이나, 현재는 크게필요하지 않음. \n",
    "        self.rootPath = rootPath\n",
    "        self.stPath = stPath\n",
    "        self.qPath = qPath\n",
    "        self.structFile = structFile\n",
    "        self.input_transform = transform #tensor로 변환\n",
    "        self.onlyDB = onlyDB\n",
    "\n",
    "        self.dbStruct = parse_dbStruct(self.structFile, self.stPath) #dataset에 대한 파일 읽기\n",
    "\n",
    "        #Test/Eval 시 WholeDataset 만으로도 수행 가능하도록 images도 선언함. (query + db) or(only db)\n",
    "        self.images = [os.path.join(self.rootPath, dbIm) for dbIm in self.dbStruct.dbImage]\n",
    "        if not onlyDB:\n",
    "            self.images += [os.path.join(self.rootPath, qIm) for qIm in self.dbStruct.qImage]\n",
    "\n",
    "        self.whichSet = self.dbStruct.whichSet  #train, test, val 중 하나\n",
    "        self.dataset = self.dbStruct.dataset   # pittsburgh250k, 30k 등\n",
    "\n",
    "        self.positives = None   #현재는 없음\n",
    "        self.distances = None   #현재는 없음\n",
    "\n",
    "\n",
    "        #mat data load and parsing\n",
    "        self.whichSet = self.dbStruct.whichSet              #train\n",
    "        self.dataset = self.dbStruct.dataset                #pittsburch250k\n",
    "        \n",
    "\n",
    "        #Dataset Class를 초기화 하면서, \n",
    "        #db관련 mat 파일을 통해 UTM좌표를 기반으로 positive와 negative를 구한다. \n",
    "\n",
    "        # 각 Threshold의 설명 \n",
    "        #  1) Trivial Pos : Positive중 Query와 너무 가까워서 제외되는 것들. < nontrivialPosDistSqThr\n",
    "        #  2) nonTrivial Pos : nonTrivialPos~PosDisThr 사이에 존재하는 Positive들\n",
    "        #  3) Negative : PosDistThr 밖의 좌표들\n",
    "        # 참조 \n",
    "        # posDistThr = matStruct[7].item()  #25\n",
    "        # posDistSqThr = matStruct[8].item() #625 --> 25^2\n",
    "        # nonTrivPosDistSqThr = matStruct[9].item() #100 -->10^2\n",
    "\n",
    "        print(\"utmDb shape:\", self.dbStruct.utmDb.shape, \"utmQ shape:\", self.dbStruct.utmQ.shape)\n",
    "        \n",
    "        knn = NearestNeighbors(n_jobs=8)\n",
    "        knn.fit(self.dbStruct.utmDb)\n",
    "\n",
    "        #거리 25m 이내의 positive 후보군들을 검색한다. \n",
    "        #기본 설정은 민코프스키 로 되어있으므로, 자동으로 유클리디안 거리가 나온다. \n",
    "        #여기서 의문은, trivial positive를 어떻게 제외하지 하는 부분이다. \n",
    "\n",
    "        PositiveDistance,PositiveIndex = knn.radius_neighbors(\n",
    "            self.dbStruct.utmQ,\n",
    "            radius=self.dbStruct.posDistThr,\n",
    "            return_distance=True\n",
    "            )\n",
    "        \n",
    "        nontrivial_positives = []\n",
    "\n",
    "        for i in range(len(PositiveIndex)):\n",
    "            fDist = PositiveDistance[i]\n",
    "            nIndex = PositiveIndex[i]\n",
    "            fDistSq = fDist ** 2\n",
    "            mask = fDistSq > self.dbStruct.nonTrivPosDistSqThr\n",
    "            #np masking 방법 https://m.blog.naver.com/baek2sm/221844619151\n",
    "            nontrivial_positives.append(nIndex[mask])\n",
    "\n",
    "        self.pos_within_Thr = PositiveIndex  #trivial 도 포함\n",
    "        self.nontrivial_pos = nontrivial_positives \n",
    "            \n",
    "        #예외처리를 위한 부분. 만약 nontrivial possitive가 없다면 해당 쿼리는 제외한다. \n",
    "        self.queries = np.where(np.array([len(x) for x in self.nontrivial_pos])>0)[0]\n",
    "\n",
    "        # Negative 후보 만들기 \n",
    "        self.potential_negatives = []        \n",
    "\n",
    "        # Index로 연산하기 위해 전체 Index를 하나 만든다. \n",
    "        self.numDbIndex = np.arange(self.dbStruct.numDb)\n",
    "\n",
    "              \n",
    "        #전체 dbImage 배열에서 Potential Positve를 뺀 나머지 배열을 만든다. \n",
    "        for pos in self.pos_within_Thr:\n",
    "            self.potential_negatives.append(\n",
    "                                            np.setdiff1d(\n",
    "                                                         self.numDbIndex, pos, \n",
    "                                                         assume_unique=True\n",
    "                                                         )\n",
    "                                            )\n",
    "\n",
    "\n",
    "        #debugging code\n",
    "        print(f\"  numDb={self.dbStruct.numDb}, numQ={self.dbStruct.numQ}\")\n",
    "        print(f\"  posDistThr={self.dbStruct.posDistThr} (m)\")\n",
    "        print(f\"  nonTrivPosDistSqThr={self.dbStruct.nonTrivPosDistSqThr} (m^2)\")\n",
    "        print(f\"  valid queries (nontrivial exists): {len(self.queries)}\")\n",
    "\n",
    "        sample_query = np.random.choice(self.queries,5,replace=False)\n",
    "        for i in sample_query:\n",
    "            print(f\"Query : {i}, Nontrivial Pos : {len(self.nontrivial_pos[i])}, Negative : {len(self.potential_negatives[i])}\")\n",
    "\n",
    "    def __len__(self):\n",
    "            return len(self.queries)\n",
    "\n",
    "    #WholeDataset 그대로 test/eval에 사용될 경우, 이미지를 출력하기 위한 필수 메서드드\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.images[index])  #dataset의 이미지를 불러와 출력\n",
    "\n",
    "        if self.input_transform:\n",
    "            img = self.input_transform(img)  #tensor로 변환한다. \n",
    "        return img, index\n",
    "\n",
    "    def getPositive(self):   #학습에선 사용하지 않음. 이후 Test/Evaluation에서 GT추출용으로 사용 \n",
    "        return self.pos_within_Thr\n",
    "\n",
    "    def getNegative(self):\n",
    "        return self.potential_negatives\n",
    "\n",
    "    def getNontrivialPositive(self):\n",
    "        return self.nontrivial_pos\n",
    "    \n",
    "    def getValidQueries(self):\n",
    "        return self.queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7bf011fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "matStruct[0] :train\n",
      "matStruct[1] :[array(['000/000021_pitch1_yaw1.jpg'], dtype='<U26')]\n",
      "matStruct[2] :[585323.61300252 585323.61300252 585323.61300252 ... 584463.92173637\n",
      " 584463.92173637 584463.92173637]\n",
      "matStruct[3] :[array(['001/001381_pitch1_yaw1.jpg'], dtype='<U26')]\n",
      "matStruct[4] :[585089.36032141 585089.36032141 585089.36032141 ... 584861.3359102\n",
      " 584861.3359102  584861.3359102 ]\n",
      "matStruct[5] :[91464]\n",
      "matStruct[6] :[7824]\n",
      "matStruct[7] :[25]\n",
      "matStruct[8] :[625]\n",
      "matStruct[9] :[100]\n",
      "utmDb shape: (91464, 2) utmQ shape: (7824, 2)\n",
      "  numDb=91464, numQ=7824\n",
      "  posDistThr=25 (m)\n",
      "  nonTrivPosDistSqThr=100 (m^2)\n",
      "  valid queries (nontrivial exists): 7824\n",
      "Query : 3753, Nontrivial Pos : 96, Negative : 91320\n",
      "Query : 3933, Nontrivial Pos : 48, Negative : 91368\n",
      "Query : 6125, Nontrivial Pos : 72, Negative : 91368\n",
      "Query : 4512, Nontrivial Pos : 48, Negative : 91368\n",
      "Query : 3584, Nontrivial Pos : 48, Negative : 91368\n"
     ]
    }
   ],
   "source": [
    "ds = WholeDatset(rootPath = root_dir, stPath=struct_dir, qPath=queries_dir, transform = input_transform(), structFile='pitts250k_train.mat')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142ae791",
   "metadata": {},
   "source": [
    "# 2. Define Network\n",
    "\n",
    "VGG16-Conv5 까지만 설정하고, \n",
    "이후 VLAD Layer를 연결한다. \n",
    "\n",
    "Network를 선언해야 feature 를 추출하고 triplet 데이터셋을 구성할 수 있다. \n",
    "Triplet 구성까지 테스트를 위해 VGG-Conv5-pooling 까지만 테스트로 구현해본다. \n",
    "\n",
    "참고자료 : https://stydy-sturdy.tistory.com/11  \n",
    "참고자료 : https://www.digitalocean.com/community/tutorials/vgg-from-scratch-pytorch  \n",
    "VGG16 논문자료 : https://arxiv.org/pdf/1409.1556  \n",
    "\n",
    "![](2026-02-25-13-52-58.png)\n",
    "\n",
    "![](2026-02-25-13-53-50.png)\n",
    "\n",
    "![](2026-02-25-14-07-56.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36a32cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1552\n",
      "<class 'torch.Tensor'> 64\n",
      "<class 'torch.Tensor'> 64\n",
      "Shape of X: torch.Size([64, 3, 480, 640])\n",
      "Shape of y : torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "feature_dataloader = DataLoader(ds,batch_size=batch_size)\n",
    "print(len(feature_dataloader))\n",
    "imgs, idx = next(iter(feature_dataloader))\n",
    "print(type(imgs[0]), len(imgs))  # PIL.Image, 64\n",
    "print(type(idx[0]), len(idx))    # int, 64\n",
    "print(f\"Shape of X: {imgs.shape}\")\n",
    "print(f\"Shape of y : {idx.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e3bce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# device\n",
    "if torch.cuda.is_available() :\n",
    "    device = 'cuda'\n",
    "else :\n",
    "    device = 'cpu'\n",
    "\n",
    "print(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd35b4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU())\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU())\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU())\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer8 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer9 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer10 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer11 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer12 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())\n",
    "        self.layer13 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(7*7*512, 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc2= nn.Sequential(\n",
    "            nn.Linear(4096, num_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
