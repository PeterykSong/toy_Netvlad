{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f36ea96",
   "metadata": {},
   "source": [
    "# NetVlad 까지 가는 Toy-project입니다. \n",
    "우선 파이토치에서부터 시작해서, NetVLAD 논문을 다시한번 확인해보고, 간단한 응용까지 구현해봅니다. \n",
    "\n",
    "torch가 설치되어있지 않다면, pip install torch 로 먼저설치해보자. torch vision도 설치 안되어있네.  \n",
    "![torch](torch.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d355f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn  #Neural network\n",
    "from torch.utils.data import DataLoader #dataset을 불러들이는 라이브러리다. \n",
    "from torchvision import datasets  #Vision에 특화된 dataset이다. 다른 라이브러리로는 torchtext, torchaudio 등 도메인에 특화된 것들이 있다. \n",
    "from torchvision.transforms import ToTensor #텐서로 변환하기 위한 라이브러리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d64ed9",
   "metadata": {},
   "source": [
    "이제 학습에 필요한 Data를 받아보자.   \n",
    "![dataDownload](download.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15ecbc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.FashionMNIST(\n",
    "    root = \"data\",\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f098a66",
   "metadata": {},
   "source": [
    "Training을 위한 데이터를 받았다면, 이제 test용 데이터도 받아보자. 자세히보면 파라미터 하나만 다르다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9631027d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.FashionMNIST(\n",
    "    root = \"test\",  #다운로드 폴더네. \n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125c4d10",
   "metadata": {},
   "source": [
    "받아지면 폴더가 몇개 생긴걸 볼 수 있다.  \n",
    "![tree](./tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f30e55",
   "metadata": {},
   "source": [
    "이제 DataLoader를 통해 데이터를 읽어들이자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2e6f343",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "117db659",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size = batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bbd71e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X[N,C,H,W] : torch.Size([64, 1, 28, 28])\n",
      "Shape of y : torch.Size([64])torch.int64\n"
     ]
    }
   ],
   "source": [
    "for X,y in test_dataloader:\n",
    "    print(f\"Shape of X[N,C,H,W] : {X.shape}\")\n",
    "    print(f\"Shape of y : {y.shape}{y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19e1dd3",
   "metadata": {},
   "source": [
    "# 모델 만들기\n",
    "\n",
    "Pytorch에서 신경망 모델은 '''nn.Module''' 을 상속받는 클래스를 생성하여 정의한다. __init__ 함수에서 신경망 계층을(Layer) 정의하고, forward 함수에서 신경망 데이터를 어떻게 전달할 것인지 지정한다. 가능한 경우 GPU 또는 MPS로 신경망을 이동시켜 연산을 가속한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5180061f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda\n"
     ]
    }
   ],
   "source": [
    "#학습에 사용할 CPU나 GPU, MPS장치를 얻자. \n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"using {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3581289",
   "metadata": {},
   "source": [
    "device에서 cpu가 떴다. cuda toolkit 설치를 확인해보자. --> 해결 봄. 5080은 nvidia-590 의 open 드라이버를 권장한다... 오픈만 되네. 오탈자 잘보자. 중괄호가 아니다. \n",
    "![cuda_error](cuda_error.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a30b83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),   #Conv1\n",
    "            nn.ReLU(),                 #Activ\n",
    "            nn.Linear(512,512),        #Conv2\n",
    "            nn.ReLU(),                 #Activ\n",
    "            nn.Linear(512,10)          #Conv3\n",
    "            # nn.ReLU(),                 #Activ\n",
    "            # nn.Linear(64,10)          #Conv3\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)  #Activ\n",
    "        logits = self.linear_relu_stack(x)     \n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "#tutorial 에서는 NeuralNetwork().to(device) 라고 되어있는데, 여기서는 지워야 돌아간다. 오타들때문에 그랬다. 잘 수정하자. \n",
    "\n",
    "print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5068a9e",
   "metadata": {},
   "source": [
    "모델이 정의되었으면, 이제 손실함수와 옵티마이저를 정의한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3a4bcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=1e-3)\n",
    "\n",
    "#시각화를 위한 설정\n",
    "result_accuracy = []\n",
    "result_accuracy.append(0)\n",
    "result_loss = []\n",
    "result_loss.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cc67cc",
   "metadata": {},
   "source": [
    "이제 학습단계를 설정해보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "483165c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model,loss_fn,optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        X,y = X.to(device),y.to(device)\n",
    "\n",
    "        #Prediction 오류 계산\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred,y)\n",
    "\n",
    "        #역전파\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(),(batch+1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "077ddb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    result_accuracy.append(correct)\n",
    "    result_loss.append(test_loss)\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47451c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.309901  [   64/60000]\n",
      "loss: 2.295172  [ 6464/60000]\n",
      "loss: 2.266313  [12864/60000]\n",
      "loss: 2.255932  [19264/60000]\n",
      "loss: 2.249127  [25664/60000]\n",
      "loss: 2.224525  [32064/60000]\n",
      "loss: 2.224824  [38464/60000]\n",
      "loss: 2.200685  [44864/60000]\n",
      "loss: 2.189038  [51264/60000]\n",
      "loss: 2.153445  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 43.5%, Avg loss: 2.149383 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.157411  [   64/60000]\n",
      "loss: 2.151746  [ 6464/60000]\n",
      "loss: 2.084206  [12864/60000]\n",
      "loss: 2.097770  [19264/60000]\n",
      "loss: 2.060265  [25664/60000]\n",
      "loss: 1.996758  [32064/60000]\n",
      "loss: 2.021587  [38464/60000]\n",
      "loss: 1.947850  [44864/60000]\n",
      "loss: 1.946434  [51264/60000]\n",
      "loss: 1.876444  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 1.873948 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.897982  [   64/60000]\n",
      "loss: 1.878255  [ 6464/60000]\n",
      "loss: 1.752188  [12864/60000]\n",
      "loss: 1.794873  [19264/60000]\n",
      "loss: 1.691284  [25664/60000]\n",
      "loss: 1.641323  [32064/60000]\n",
      "loss: 1.659332  [38464/60000]\n",
      "loss: 1.567655  [44864/60000]\n",
      "loss: 1.593908  [51264/60000]\n",
      "loss: 1.489094  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 1.506288 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.564382  [   64/60000]\n",
      "loss: 1.540084  [ 6464/60000]\n",
      "loss: 1.386836  [12864/60000]\n",
      "loss: 1.458483  [19264/60000]\n",
      "loss: 1.342500  [25664/60000]\n",
      "loss: 1.342006  [32064/60000]\n",
      "loss: 1.347608  [38464/60000]\n",
      "loss: 1.283611  [44864/60000]\n",
      "loss: 1.324685  [51264/60000]\n",
      "loss: 1.218585  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.7%, Avg loss: 1.246438 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.319854  [   64/60000]\n",
      "loss: 1.306396  [ 6464/60000]\n",
      "loss: 1.141289  [12864/60000]\n",
      "loss: 1.241622  [19264/60000]\n",
      "loss: 1.122107  [25664/60000]\n",
      "loss: 1.149565  [32064/60000]\n",
      "loss: 1.161021  [38464/60000]\n",
      "loss: 1.108712  [44864/60000]\n",
      "loss: 1.156695  [51264/60000]\n",
      "loss: 1.062397  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.9%, Avg loss: 1.085119 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.155139  [   64/60000]\n",
      "loss: 1.158949  [ 6464/60000]\n",
      "loss: 0.977610  [12864/60000]\n",
      "loss: 1.104982  [19264/60000]\n",
      "loss: 0.986284  [25664/60000]\n",
      "loss: 1.018300  [32064/60000]\n",
      "loss: 1.047480  [38464/60000]\n",
      "loss: 0.997344  [44864/60000]\n",
      "loss: 1.046468  [51264/60000]\n",
      "loss: 0.964535  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.1%, Avg loss: 0.979935 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.038019  [   64/60000]\n",
      "loss: 1.061642  [ 6464/60000]\n",
      "loss: 0.863509  [12864/60000]\n",
      "loss: 1.012639  [19264/60000]\n",
      "loss: 0.899609  [25664/60000]\n",
      "loss: 0.923923  [32064/60000]\n",
      "loss: 0.973352  [38464/60000]\n",
      "loss: 0.924185  [44864/60000]\n",
      "loss: 0.969193  [51264/60000]\n",
      "loss: 0.897731  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.907197 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.950242  [   64/60000]\n",
      "loss: 0.992938  [ 6464/60000]\n",
      "loss: 0.780917  [12864/60000]\n",
      "loss: 0.946830  [19264/60000]\n",
      "loss: 0.841737  [25664/60000]\n",
      "loss: 0.854607  [32064/60000]\n",
      "loss: 0.920985  [38464/60000]\n",
      "loss: 0.874878  [44864/60000]\n",
      "loss: 0.913168  [51264/60000]\n",
      "loss: 0.849259  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.5%, Avg loss: 0.854472 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.882508  [   64/60000]\n",
      "loss: 0.941253  [ 6464/60000]\n",
      "loss: 0.719023  [12864/60000]\n",
      "loss: 0.897796  [19264/60000]\n",
      "loss: 0.800590  [25664/60000]\n",
      "loss: 0.802690  [32064/60000]\n",
      "loss: 0.881017  [38464/60000]\n",
      "loss: 0.840188  [44864/60000]\n",
      "loss: 0.871304  [51264/60000]\n",
      "loss: 0.812270  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.6%, Avg loss: 0.814391 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.828560  [   64/60000]\n",
      "loss: 0.899941  [ 6464/60000]\n",
      "loss: 0.671025  [12864/60000]\n",
      "loss: 0.859896  [19264/60000]\n",
      "loss: 0.769409  [25664/60000]\n",
      "loss: 0.762846  [32064/60000]\n",
      "loss: 0.848541  [38464/60000]\n",
      "loss: 0.814349  [44864/60000]\n",
      "loss: 0.838968  [51264/60000]\n",
      "loss: 0.782644  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.9%, Avg loss: 0.782572 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.783925  [   64/60000]\n",
      "loss: 0.865032  [ 6464/60000]\n",
      "loss: 0.632423  [12864/60000]\n",
      "loss: 0.829674  [19264/60000]\n",
      "loss: 0.744308  [25664/60000]\n",
      "loss: 0.731829  [32064/60000]\n",
      "loss: 0.820716  [38464/60000]\n",
      "loss: 0.793806  [44864/60000]\n",
      "loss: 0.812901  [51264/60000]\n",
      "loss: 0.757817  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 72.1%, Avg loss: 0.756155 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.746110  [   64/60000]\n",
      "loss: 0.834339  [ 6464/60000]\n",
      "loss: 0.600292  [12864/60000]\n",
      "loss: 0.804837  [19264/60000]\n",
      "loss: 0.723194  [25664/60000]\n",
      "loss: 0.706994  [32064/60000]\n",
      "loss: 0.795924  [38464/60000]\n",
      "loss: 0.776532  [44864/60000]\n",
      "loss: 0.791198  [51264/60000]\n",
      "loss: 0.736280  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 0.733385 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.713367  [   64/60000]\n",
      "loss: 0.806524  [ 6464/60000]\n",
      "loss: 0.572859  [12864/60000]\n",
      "loss: 0.783801  [19264/60000]\n",
      "loss: 0.705007  [25664/60000]\n",
      "loss: 0.686597  [32064/60000]\n",
      "loss: 0.773308  [38464/60000]\n",
      "loss: 0.761241  [44864/60000]\n",
      "loss: 0.772521  [51264/60000]\n",
      "loss: 0.717123  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 74.3%, Avg loss: 0.713223 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.684451  [   64/60000]\n",
      "loss: 0.780880  [ 6464/60000]\n",
      "loss: 0.548929  [12864/60000]\n",
      "loss: 0.765441  [19264/60000]\n",
      "loss: 0.689034  [25664/60000]\n",
      "loss: 0.669492  [32064/60000]\n",
      "loss: 0.752261  [38464/60000]\n",
      "loss: 0.747467  [44864/60000]\n",
      "loss: 0.756021  [51264/60000]\n",
      "loss: 0.699739  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 0.695044 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.658758  [   64/60000]\n",
      "loss: 0.757202  [ 6464/60000]\n",
      "loss: 0.527724  [12864/60000]\n",
      "loss: 0.749109  [19264/60000]\n",
      "loss: 0.674835  [25664/60000]\n",
      "loss: 0.654831  [32064/60000]\n",
      "loss: 0.732560  [38464/60000]\n",
      "loss: 0.734941  [44864/60000]\n",
      "loss: 0.741346  [51264/60000]\n",
      "loss: 0.683728  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 75.9%, Avg loss: 0.678481 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.635777  [   64/60000]\n",
      "loss: 0.735347  [ 6464/60000]\n",
      "loss: 0.508872  [12864/60000]\n",
      "loss: 0.734295  [19264/60000]\n",
      "loss: 0.662153  [25664/60000]\n",
      "loss: 0.642147  [32064/60000]\n",
      "loss: 0.714122  [38464/60000]\n",
      "loss: 0.723703  [44864/60000]\n",
      "loss: 0.728396  [51264/60000]\n",
      "loss: 0.669071  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 76.6%, Avg loss: 0.663339 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.615026  [   64/60000]\n",
      "loss: 0.715115  [ 6464/60000]\n",
      "loss: 0.492026  [12864/60000]\n",
      "loss: 0.720677  [19264/60000]\n",
      "loss: 0.650844  [25664/60000]\n",
      "loss: 0.631179  [32064/60000]\n",
      "loss: 0.696821  [38464/60000]\n",
      "loss: 0.713591  [44864/60000]\n",
      "loss: 0.717051  [51264/60000]\n",
      "loss: 0.655559  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.0%, Avg loss: 0.649514 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.596427  [   64/60000]\n",
      "loss: 0.696571  [ 6464/60000]\n",
      "loss: 0.476875  [12864/60000]\n",
      "loss: 0.708228  [19264/60000]\n",
      "loss: 0.640874  [25664/60000]\n",
      "loss: 0.621610  [32064/60000]\n",
      "loss: 0.680650  [38464/60000]\n",
      "loss: 0.704539  [44864/60000]\n",
      "loss: 0.707211  [51264/60000]\n",
      "loss: 0.642955  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.636887 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.579711  [   64/60000]\n",
      "loss: 0.679595  [ 6464/60000]\n",
      "loss: 0.463195  [12864/60000]\n",
      "loss: 0.696762  [19264/60000]\n",
      "loss: 0.631888  [25664/60000]\n",
      "loss: 0.613131  [32064/60000]\n",
      "loss: 0.665750  [38464/60000]\n",
      "loss: 0.696877  [44864/60000]\n",
      "loss: 0.698621  [51264/60000]\n",
      "loss: 0.631099  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 77.9%, Avg loss: 0.625355 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.564748  [   64/60000]\n",
      "loss: 0.664089  [ 6464/60000]\n",
      "loss: 0.450839  [12864/60000]\n",
      "loss: 0.686227  [19264/60000]\n",
      "loss: 0.623743  [25664/60000]\n",
      "loss: 0.605542  [32064/60000]\n",
      "loss: 0.652040  [38464/60000]\n",
      "loss: 0.690392  [44864/60000]\n",
      "loss: 0.691187  [51264/60000]\n",
      "loss: 0.619933  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.614827 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.551214  [   64/60000]\n",
      "loss: 0.649819  [ 6464/60000]\n",
      "loss: 0.439703  [12864/60000]\n",
      "loss: 0.676454  [19264/60000]\n",
      "loss: 0.616251  [25664/60000]\n",
      "loss: 0.598698  [32064/60000]\n",
      "loss: 0.639339  [38464/60000]\n",
      "loss: 0.684970  [44864/60000]\n",
      "loss: 0.684707  [51264/60000]\n",
      "loss: 0.609483  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.605198 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.538854  [   64/60000]\n",
      "loss: 0.636875  [ 6464/60000]\n",
      "loss: 0.429594  [12864/60000]\n",
      "loss: 0.667265  [19264/60000]\n",
      "loss: 0.609104  [25664/60000]\n",
      "loss: 0.592386  [32064/60000]\n",
      "loss: 0.627597  [38464/60000]\n",
      "loss: 0.680512  [44864/60000]\n",
      "loss: 0.679111  [51264/60000]\n",
      "loss: 0.599513  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.596376 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.527586  [   64/60000]\n",
      "loss: 0.625030  [ 6464/60000]\n",
      "loss: 0.420359  [12864/60000]\n",
      "loss: 0.658541  [19264/60000]\n",
      "loss: 0.602215  [25664/60000]\n",
      "loss: 0.586482  [32064/60000]\n",
      "loss: 0.616673  [38464/60000]\n",
      "loss: 0.676935  [44864/60000]\n",
      "loss: 0.674308  [51264/60000]\n",
      "loss: 0.589912  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.588268 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.517223  [   64/60000]\n",
      "loss: 0.614150  [ 6464/60000]\n",
      "loss: 0.411839  [12864/60000]\n",
      "loss: 0.650341  [19264/60000]\n",
      "loss: 0.595569  [25664/60000]\n",
      "loss: 0.580992  [32064/60000]\n",
      "loss: 0.606615  [38464/60000]\n",
      "loss: 0.674144  [44864/60000]\n",
      "loss: 0.670273  [51264/60000]\n",
      "loss: 0.580684  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.580803 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.507591  [   64/60000]\n",
      "loss: 0.604111  [ 6464/60000]\n",
      "loss: 0.403965  [12864/60000]\n",
      "loss: 0.642572  [19264/60000]\n",
      "loss: 0.589108  [25664/60000]\n",
      "loss: 0.575691  [32064/60000]\n",
      "loss: 0.597276  [38464/60000]\n",
      "loss: 0.672029  [44864/60000]\n",
      "loss: 0.666691  [51264/60000]\n",
      "loss: 0.571805  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.573892 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.498609  [   64/60000]\n",
      "loss: 0.594881  [ 6464/60000]\n",
      "loss: 0.396628  [12864/60000]\n",
      "loss: 0.635146  [19264/60000]\n",
      "loss: 0.582699  [25664/60000]\n",
      "loss: 0.570494  [32064/60000]\n",
      "loss: 0.588511  [38464/60000]\n",
      "loss: 0.670458  [44864/60000]\n",
      "loss: 0.663535  [51264/60000]\n",
      "loss: 0.563272  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.567477 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.490314  [   64/60000]\n",
      "loss: 0.586429  [ 6464/60000]\n",
      "loss: 0.389828  [12864/60000]\n",
      "loss: 0.627916  [19264/60000]\n",
      "loss: 0.576479  [25664/60000]\n",
      "loss: 0.565326  [32064/60000]\n",
      "loss: 0.580471  [38464/60000]\n",
      "loss: 0.669555  [44864/60000]\n",
      "loss: 0.660781  [51264/60000]\n",
      "loss: 0.554884  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.561533 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.482432  [   64/60000]\n",
      "loss: 0.578571  [ 6464/60000]\n",
      "loss: 0.383552  [12864/60000]\n",
      "loss: 0.621102  [19264/60000]\n",
      "loss: 0.570339  [25664/60000]\n",
      "loss: 0.560377  [32064/60000]\n",
      "loss: 0.573014  [38464/60000]\n",
      "loss: 0.668999  [44864/60000]\n",
      "loss: 0.658440  [51264/60000]\n",
      "loss: 0.546771  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.555994 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.474799  [   64/60000]\n",
      "loss: 0.571269  [ 6464/60000]\n",
      "loss: 0.377742  [12864/60000]\n",
      "loss: 0.614655  [19264/60000]\n",
      "loss: 0.564307  [25664/60000]\n",
      "loss: 0.555578  [32064/60000]\n",
      "loss: 0.566153  [38464/60000]\n",
      "loss: 0.668827  [44864/60000]\n",
      "loss: 0.656250  [51264/60000]\n",
      "loss: 0.538960  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 80.9%, Avg loss: 0.550818 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.467652  [   64/60000]\n",
      "loss: 0.564518  [ 6464/60000]\n",
      "loss: 0.372332  [12864/60000]\n",
      "loss: 0.608482  [19264/60000]\n",
      "loss: 0.558339  [25664/60000]\n",
      "loss: 0.550820  [32064/60000]\n",
      "loss: 0.559755  [38464/60000]\n",
      "loss: 0.668818  [44864/60000]\n",
      "loss: 0.654262  [51264/60000]\n",
      "loss: 0.531424  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.545969 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.460767  [   64/60000]\n",
      "loss: 0.558314  [ 6464/60000]\n",
      "loss: 0.367268  [12864/60000]\n",
      "loss: 0.602613  [19264/60000]\n",
      "loss: 0.552530  [25664/60000]\n",
      "loss: 0.546143  [32064/60000]\n",
      "loss: 0.553769  [38464/60000]\n",
      "loss: 0.668949  [44864/60000]\n",
      "loss: 0.652369  [51264/60000]\n",
      "loss: 0.524214  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.541432 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.454244  [   64/60000]\n",
      "loss: 0.552568  [ 6464/60000]\n",
      "loss: 0.362460  [12864/60000]\n",
      "loss: 0.596981  [19264/60000]\n",
      "loss: 0.546782  [25664/60000]\n",
      "loss: 0.541573  [32064/60000]\n",
      "loss: 0.548067  [38464/60000]\n",
      "loss: 0.669170  [44864/60000]\n",
      "loss: 0.650494  [51264/60000]\n",
      "loss: 0.517317  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.537186 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.447939  [   64/60000]\n",
      "loss: 0.547197  [ 6464/60000]\n",
      "loss: 0.357915  [12864/60000]\n",
      "loss: 0.591644  [19264/60000]\n",
      "loss: 0.541148  [25664/60000]\n",
      "loss: 0.537079  [32064/60000]\n",
      "loss: 0.542696  [38464/60000]\n",
      "loss: 0.669479  [44864/60000]\n",
      "loss: 0.648649  [51264/60000]\n",
      "loss: 0.510699  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.4%, Avg loss: 0.533190 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.441946  [   64/60000]\n",
      "loss: 0.542187  [ 6464/60000]\n",
      "loss: 0.353568  [12864/60000]\n",
      "loss: 0.586484  [19264/60000]\n",
      "loss: 0.535541  [25664/60000]\n",
      "loss: 0.532622  [32064/60000]\n",
      "loss: 0.537622  [38464/60000]\n",
      "loss: 0.669833  [44864/60000]\n",
      "loss: 0.646840  [51264/60000]\n",
      "loss: 0.504296  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.529426 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.436173  [   64/60000]\n",
      "loss: 0.537544  [ 6464/60000]\n",
      "loss: 0.349457  [12864/60000]\n",
      "loss: 0.581536  [19264/60000]\n",
      "loss: 0.530008  [25664/60000]\n",
      "loss: 0.528138  [32064/60000]\n",
      "loss: 0.532794  [38464/60000]\n",
      "loss: 0.670213  [44864/60000]\n",
      "loss: 0.645095  [51264/60000]\n",
      "loss: 0.498204  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.6%, Avg loss: 0.525872 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.430605  [   64/60000]\n",
      "loss: 0.533182  [ 6464/60000]\n",
      "loss: 0.345605  [12864/60000]\n",
      "loss: 0.576742  [19264/60000]\n",
      "loss: 0.524626  [25664/60000]\n",
      "loss: 0.523744  [32064/60000]\n",
      "loss: 0.528234  [38464/60000]\n",
      "loss: 0.670582  [44864/60000]\n",
      "loss: 0.643357  [51264/60000]\n",
      "loss: 0.492366  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.7%, Avg loss: 0.522512 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.425248  [   64/60000]\n",
      "loss: 0.529097  [ 6464/60000]\n",
      "loss: 0.341953  [12864/60000]\n",
      "loss: 0.572108  [19264/60000]\n",
      "loss: 0.519394  [25664/60000]\n",
      "loss: 0.519406  [32064/60000]\n",
      "loss: 0.523947  [38464/60000]\n",
      "loss: 0.670918  [44864/60000]\n",
      "loss: 0.641604  [51264/60000]\n",
      "loss: 0.486784  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.519336 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.420086  [   64/60000]\n",
      "loss: 0.525290  [ 6464/60000]\n",
      "loss: 0.338470  [12864/60000]\n",
      "loss: 0.567658  [19264/60000]\n",
      "loss: 0.514387  [25664/60000]\n",
      "loss: 0.515224  [32064/60000]\n",
      "loss: 0.519874  [38464/60000]\n",
      "loss: 0.671166  [44864/60000]\n",
      "loss: 0.639861  [51264/60000]\n",
      "loss: 0.481479  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.516324 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.415108  [   64/60000]\n",
      "loss: 0.521735  [ 6464/60000]\n",
      "loss: 0.335152  [12864/60000]\n",
      "loss: 0.563369  [19264/60000]\n",
      "loss: 0.509478  [25664/60000]\n",
      "loss: 0.511180  [32064/60000]\n",
      "loss: 0.516010  [38464/60000]\n",
      "loss: 0.671277  [44864/60000]\n",
      "loss: 0.638083  [51264/60000]\n",
      "loss: 0.476421  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 81.9%, Avg loss: 0.513466 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.410223  [   64/60000]\n",
      "loss: 0.518425  [ 6464/60000]\n",
      "loss: 0.331958  [12864/60000]\n",
      "loss: 0.559147  [19264/60000]\n",
      "loss: 0.504768  [25664/60000]\n",
      "loss: 0.507165  [32064/60000]\n",
      "loss: 0.512336  [38464/60000]\n",
      "loss: 0.671262  [44864/60000]\n",
      "loss: 0.636297  [51264/60000]\n",
      "loss: 0.471554  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.0%, Avg loss: 0.510749 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.405483  [   64/60000]\n",
      "loss: 0.515274  [ 6464/60000]\n",
      "loss: 0.328909  [12864/60000]\n",
      "loss: 0.555048  [19264/60000]\n",
      "loss: 0.500239  [25664/60000]\n",
      "loss: 0.503246  [32064/60000]\n",
      "loss: 0.508834  [38464/60000]\n",
      "loss: 0.671111  [44864/60000]\n",
      "loss: 0.634475  [51264/60000]\n",
      "loss: 0.466977  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.508159 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.400914  [   64/60000]\n",
      "loss: 0.512290  [ 6464/60000]\n",
      "loss: 0.325989  [12864/60000]\n",
      "loss: 0.551084  [19264/60000]\n",
      "loss: 0.495843  [25664/60000]\n",
      "loss: 0.499446  [32064/60000]\n",
      "loss: 0.505480  [38464/60000]\n",
      "loss: 0.670801  [44864/60000]\n",
      "loss: 0.632614  [51264/60000]\n",
      "loss: 0.462620  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.505689 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.396481  [   64/60000]\n",
      "loss: 0.509421  [ 6464/60000]\n",
      "loss: 0.323201  [12864/60000]\n",
      "loss: 0.547258  [19264/60000]\n",
      "loss: 0.491571  [25664/60000]\n",
      "loss: 0.495753  [32064/60000]\n",
      "loss: 0.502313  [38464/60000]\n",
      "loss: 0.670415  [44864/60000]\n",
      "loss: 0.630772  [51264/60000]\n",
      "loss: 0.458483  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.503329 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.392149  [   64/60000]\n",
      "loss: 0.506683  [ 6464/60000]\n",
      "loss: 0.320522  [12864/60000]\n",
      "loss: 0.543551  [19264/60000]\n",
      "loss: 0.487506  [25664/60000]\n",
      "loss: 0.492180  [32064/60000]\n",
      "loss: 0.499222  [38464/60000]\n",
      "loss: 0.669885  [44864/60000]\n",
      "loss: 0.628884  [51264/60000]\n",
      "loss: 0.454605  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.501069 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.387938  [   64/60000]\n",
      "loss: 0.504074  [ 6464/60000]\n",
      "loss: 0.317959  [12864/60000]\n",
      "loss: 0.539966  [19264/60000]\n",
      "loss: 0.483528  [25664/60000]\n",
      "loss: 0.488736  [32064/60000]\n",
      "loss: 0.496271  [38464/60000]\n",
      "loss: 0.669204  [44864/60000]\n",
      "loss: 0.626955  [51264/60000]\n",
      "loss: 0.450947  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.3%, Avg loss: 0.498902 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.383830  [   64/60000]\n",
      "loss: 0.501582  [ 6464/60000]\n",
      "loss: 0.315487  [12864/60000]\n",
      "loss: 0.536494  [19264/60000]\n",
      "loss: 0.479687  [25664/60000]\n",
      "loss: 0.485398  [32064/60000]\n",
      "loss: 0.493430  [38464/60000]\n",
      "loss: 0.668349  [44864/60000]\n",
      "loss: 0.624947  [51264/60000]\n",
      "loss: 0.447511  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.4%, Avg loss: 0.496817 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.379802  [   64/60000]\n",
      "loss: 0.499190  [ 6464/60000]\n",
      "loss: 0.313086  [12864/60000]\n",
      "loss: 0.533142  [19264/60000]\n",
      "loss: 0.475970  [25664/60000]\n",
      "loss: 0.482174  [32064/60000]\n",
      "loss: 0.490673  [38464/60000]\n",
      "loss: 0.667395  [44864/60000]\n",
      "loss: 0.622914  [51264/60000]\n",
      "loss: 0.444221  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.494806 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.375902  [   64/60000]\n",
      "loss: 0.496888  [ 6464/60000]\n",
      "loss: 0.310734  [12864/60000]\n",
      "loss: 0.529919  [19264/60000]\n",
      "loss: 0.472333  [25664/60000]\n",
      "loss: 0.479117  [32064/60000]\n",
      "loss: 0.488027  [38464/60000]\n",
      "loss: 0.666341  [44864/60000]\n",
      "loss: 0.620945  [51264/60000]\n",
      "loss: 0.440979  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.492868 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.372138  [   64/60000]\n",
      "loss: 0.494639  [ 6464/60000]\n",
      "loss: 0.308480  [12864/60000]\n",
      "loss: 0.526846  [19264/60000]\n",
      "loss: 0.468830  [25664/60000]\n",
      "loss: 0.476184  [32064/60000]\n",
      "loss: 0.485489  [38464/60000]\n",
      "loss: 0.665155  [44864/60000]\n",
      "loss: 0.619057  [51264/60000]\n",
      "loss: 0.437968  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.491008 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.368452  [   64/60000]\n",
      "loss: 0.492434  [ 6464/60000]\n",
      "loss: 0.306268  [12864/60000]\n",
      "loss: 0.523886  [19264/60000]\n",
      "loss: 0.465478  [25664/60000]\n",
      "loss: 0.473399  [32064/60000]\n",
      "loss: 0.483040  [38464/60000]\n",
      "loss: 0.663871  [44864/60000]\n",
      "loss: 0.617177  [51264/60000]\n",
      "loss: 0.435136  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.489216 \n",
      "\n",
      "Done!\n",
      "Accuracy : [0, 0.435, 0.5746, 0.6196, 0.6368, 0.6489, 0.6613, 0.6737, 0.6853, 0.6958, 0.7087, 0.7208, 0.7334, 0.7433, 0.7516, 0.7593, 0.7656, 0.7705, 0.7748, 0.7786, 0.7825, 0.786, 0.7897, 0.7932, 0.795, 0.7978, 0.8007, 0.8029, 0.8064, 0.8088, 0.8101, 0.8115, 0.8132, 0.8143, 0.8152, 0.8157, 0.8168, 0.818, 0.818, 0.8194, 0.8199, 0.8206, 0.8214, 0.823, 0.8231, 0.8232, 0.8242, 0.8251, 0.8256, 0.8264, 0.8263]\n",
      "Loss : [0, 2.149382612507814, 1.873947913479653, 1.5062884623837318, 1.2464375419981162, 1.0851190951979084, 0.9799348218425824, 0.9071974735351125, 0.854471951533275, 0.8143913652866509, 0.7825720864496414, 0.7561546383769648, 0.7333853073940155, 0.7132233229412395, 0.6950435553007065, 0.6784806811505821, 0.6633392095945443, 0.6495139029375308, 0.6368869996754227, 0.6253547789944205, 0.6148265807112311, 0.6051984879241628, 0.5963764088169025, 0.5882684913030856, 0.5808027967525895, 0.5738921584976706, 0.5674774606896055, 0.5615326390144931, 0.55599405906003, 0.5508176965318667, 0.5459685439516784, 0.5414323332203421, 0.5371859365967429, 0.5331900656982592, 0.5294262671926219, 0.5258717738139401, 0.5225118634047782, 0.5193363173752074, 0.5163241909567717, 0.5134661926585398, 0.5107493645446316, 0.5081591934535155, 0.5056893736313862, 0.5033286980762604, 0.5010690916875365, 0.498901507657045, 0.49681716967540185, 0.49480612927181705, 0.49286834126824786, 0.4910080945415861, 0.48921554882055635]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epochs = 50\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")\n",
    "print(f\"Accuracy : {result_accuracy}\")\n",
    "print(f\"Loss : {result_loss}\")\n",
    "x = [i for i in range(len(result_accuracy))]\n",
    "plt.plot(x,result_accuracy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c38715a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb1c0c6",
   "metadata": {},
   "source": [
    "데이터셋을 한번 시각화해보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29bb728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train_data), size=(1,)).item()\n",
    "    img, label = train_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6ec720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def custom_imshow(img):\n",
    "    img = img.numpy()\n",
    "    print(len(img))\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process():\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_dataloader):\n",
    "        print(batch_idx)\n",
    "        custom_imshow(inputs[0])\n",
    "\n",
    "\n",
    "process()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
